{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 1 : PAC Learnability, Hypothesis, Regression\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Total Points: **100**\n",
        "\n",
        "Tentative Weightage : **9%**\n",
        "\n",
        "Submission Deadline :  **$21^{st}$ Feburary 2024 , 10:00 AM** (3 weeks)\n",
        "\n",
        "Submit a separate report to mention any observations asked in the corresponding questions. Without these observations, no points will be provided for the corresponding question.\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "General Instructions:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1. You have to do this lab individually\n",
        "2. You may use **seaborn, matplotlib, pandas, numpy, csv**\n",
        "3. All the code should be submitted in the form of a single Jupyter notebook itself.\n",
        "4. Points for each sub-section are mentioned in the appropriate question.\n",
        "5. You can use Google colab to run a jupyter notebook (https://colab.research.google.com/) You can also run it in your local anaconda jupyter notebook.\n",
        "6. The lab must be submitted on Google classroom. The code as well as the accompanying observations (report pdf) should be made part of the assignment.\n",
        "7. **Code Readability** is very important. Modularize your code by making use of classes, functions that can be flexibly reused wherever necessary. Also use self explanatory variable names and add comments to describe your approach wherever necessary. You may add additional code or text blocks as necessary.\n",
        "8. You are expected to submit your **observations** (preferably in a separate pdf file) and not just an error free code.\n",
        "9. Students are expected to follow the **honor code** of the class.\n",
        "10. The deadline is strict and any assignment submitted later will not\n",
        "be consider for evaluation unless you take prior permission (at least 4 days before the submission deadline).\n",
        "11. The marks will be given on the basis of quality of code, use of innovative data structures, scalability, correctness, and completeness of the reported observation.\n",
        "12. In case of any queries regarding Lab 1, please mail the TAs (emails are provided on the google classroom).\n",
        "\n",
        "**Best Wishes**\n"
      ],
      "metadata": {
        "id": "AfXDKalbnzFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TASK 1</h1>"
      ],
      "metadata": {
        "id": "RBKxAFkBgP34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 1**: Harmony in Frames                                                      **(40 Marks)**\n",
        "\n",
        "\n",
        "(a) Consider the set of sorted points $x_1, x_2, \\ldots, x_n$ sampled independently and identically from Uniform distribution from range $0$ to $1$. For simplicity, let us look into problem where corresponding labels ($y_i$) to each $x_i, \\forall i\\in [n]$ is either positive ($1$) or negative ($0$).  \n",
        "\n",
        "\n",
        "(b) Further, consider a class of hypothesis ($H_k$) that consider countable union of $k$ non-overlapping partitions (called frames). Particularly, for instance a set of such partitions is denoted as $P = \\{[a_1, b_1], \\ldots, [a_k, b_k]$ where $0 \\le a_1 \\le b_1 \\le a_2 \\le \\ldots \\le a_k \\le b_k \\le 1$. Then any hypothesis $h_P \\in H_k$ is given as\n",
        "<br>\n",
        "<br>\n",
        "$h_P = \\begin{cases}\n",
        "    1\\ \\ \\  \\text{   if } x \\in [a_1, b_1] \\text{ or }  [a_2, b_2] \\text{ or } \\ldots, [a_k, b_k] \\\\\n",
        "    0\\ \\ \\  \\text{   otherwise }\n",
        "\\end{cases}$\n",
        "\n",
        "(c) As you have a collection of data points $(x_1, y_1), \\ldots, (x_n, y_n)$ where $x_i$'s are uniformly distributed on space $0$ to $1$, let us now look into probability distribution of labels $y_i$'s to each of the $x_i$'s i.e., the true distribution $P(x, y) = P(y | x) P(x)$ is given as below:\n",
        "<br>\n",
        "<br>\n",
        "$\\mathcal{P}(y= \\text{positive} | x) = \\begin{cases} 0.7\\ \\   \\text{ if } x \\in [0, 0.2] \\cup  [0.4, 0.6] \\cup \\ldots, [0.8, 1] \\\\\n",
        "0.2\\ \\  \\text{ if } x \\in (0.2, 0.4) \\cup  (0.6, 0.8) \\\\\n",
        "\\end{cases}\n",
        "$\n",
        "<br><br>\n",
        "and $\\mathcal{P}(y= \\text{negative} | x) = 1 - \\mathcal{P}(y= \\text{positive} | x)$.\n",
        "\n",
        "<br><br>\n",
        "Now, as you have gathered complete prerequisite knowledge for the question, let us look into the sub-tasks which needs to be performed as part of this lab assignment.  \n",
        "<br><br>\n",
        "We have provided you with a snippet [called PartitionRaja_Discover($\\cdot$)] that returns the best possible tuple of $k$ partitions on given sorted list of $X$ values and corresponding labels $Y$ for a fixed $k$.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**SubTask 1**: Code the procedure SUBTASK1 that takes as input a list of partitions $P$, computes the true error and empirical error.  \n",
        "                                          **(15 Marks + 5 Marks respectively)**\n",
        "\n",
        " Now, fix $k$=$3$ and vary number of data points  $n=10, 20, \\ldots, 200$. For each value of $n$ find the mean and standard deviation of emprirical, true error over 10 independent runs. Plot these both error values against $n$.  \n",
        "                                                                  **(7 Marks)**\n",
        "\n",
        " Discuss your findings in the report.                             **(3 Marks)**\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "**SubTask 2**: Sample a dataset of size $n=1500$. Find the best emprical risk minimizer hypothesis using code snippted provided for different $k$ values from $1, 2, 3, \\ldots, 10$. Plot the mean and standard deviation of emprirical, true error over 10 independent runs. Plot these both error values against $k$.  \n",
        " **(7 Marks)**\n",
        "\n",
        "Discuss your findings in the report.  Find the best $k^*$ and report your reason for choice of same.  **(3 Marks)**\n",
        "\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "NOTE: You have to complete the subroutines for completion of this question. Further, each independent run in Subtask 1 is referred as follows:<br><br>\n",
        "\n",
        "import random<br>\n",
        "import numpy as np<br>\n",
        "seeds = [0,100,200,300]<br>\n",
        "mean_over_n =[]<br>\n",
        "std_over_n =[]<br>\n",
        "<br>\n",
        "for n in range(10, 210, 10):<br>\n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;answers =[]<br>\n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;for seed in seeds:<br>\n",
        "      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;np.random.seed(seed)<br>\n",
        "      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;random.seed(seed)<br>\n",
        "      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ans = A()<br>\n",
        "      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;answers.append(ans)<br>\n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;mean_over_n.append(np.mean(answers))<br>\n",
        "  &nbsp;&nbsp;&nbsp;&nbsp;std_over_n.append(np.std(answers))<br>\n",
        "\n",
        "Now plot these mean_over_n and std_over_n using error plots in matplotlib\n",
        "\n",
        "<br>\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "30sWC2xEsc7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import *\n",
        "\n",
        "def PartitionRaja_Discover(X, Y, k):\n",
        "\n",
        "    assert all(array(X) == array(sorted(X))), \"X must be sorted!\"\n",
        "\n",
        "    X = array(X)\n",
        "    Y = array(Y)\n",
        "    m = len(X)\n",
        "    DP1 = [[None for j in range(k+1)] for i in range(m+1)]\n",
        "    DP2 = zeros((m+1, k+1), dtype=int)\n",
        "\n",
        "    cuml_sum_y = concatenate([[0], cumsum(Y)])\n",
        "\n",
        "    DP2[:m+1,0] = cuml_sum_y\n",
        "\n",
        "    for i in range(1, m+1):\n",
        "        for j in range(1, k+1):\n",
        "            choices = []\n",
        "            for l in range(0,i+1):\n",
        "                nxt_errs = DP2[l,j-1] + (cuml_sum_y[i]-cuml_sum_y[l]) + concatenate([[0], cumsum((-1)**(Y[arange(l, i)] == 1))])\n",
        "                min_err = argmin(nxt_errs)\n",
        "                choices.append((nxt_errs[min_err], (l, arange(l,i+1)[min_err])))\n",
        "\n",
        "            DP2[i,j], DP1[i][j] = min(choices)\n",
        "\n",
        "    good = []\n",
        "    cur = DP1[m][k]\n",
        "    for i in range(k,0,-1):\n",
        "        good.append(cur)\n",
        "        cur = DP1[cur[0]][i-1]\n",
        "        if cur == None:\n",
        "            break\n",
        "    good = sorted(good)\n",
        "    temp = concatenate([[0], X, [1]])\n",
        "    reps = (temp[1:]+temp[:-1]) / 2.0\n",
        "    partitions = [(reps[a], reps[b]) for a,b in good]\n",
        "\n",
        "    return partitions"
      ],
      "metadata": {
        "id": "hM7trq4Z_J4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Complete the following subroutines as part of assignment\n",
        "\n",
        "def form_a_dataset(number_of_samples):\n",
        "\n",
        "  '''\n",
        "     Input: Takes in an integer which tells total number of points to be generated in dataset\n",
        "\n",
        "     Output: Returns list of data points [(x1,y1), (x2,y2), ..., (xn,yn)]\n",
        "\n",
        "  '''\n",
        "\n",
        "  pass\n",
        "\n",
        "\n",
        "def find_true_error(partitions,X,Y):\n",
        "\n",
        "  '''\n",
        "     Input: Takes in parition (ie, hypothesis), set of X points and their true label Y\n",
        "\n",
        "     Output: Returns empirical error\n",
        "\n",
        "     You can change the inputs as per your need and requirements. This is just sample.\n",
        "\n",
        "  '''\n",
        "\n",
        "  pass\n",
        "\n",
        "\n",
        "def find_empirical_error(partitions, X, Y):\n",
        "\n",
        "  '''\n",
        "     Input: Takes in parition (ie, hypothesis), set of X points and their true label Y\n",
        "\n",
        "     Output: Returns empirical error\n",
        "\n",
        "     You can change the inputs as per your need and requirements. This is just sample.\n",
        "\n",
        "  '''\n",
        "\n",
        "  pass\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aKgThuTq_Jz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def SUBTASK1():\n",
        "\n",
        "  '''\n",
        "     fix k=3 and vary number of data points  $n=10, 20,..., 200$.\n",
        "     For each value of $n$ find the mean and standard deviation of emprirical, true error over 10 independent runs.\n",
        "     Plot these both error values against n.\n",
        "\n",
        "     You can change the inputs as per your need and requirements. This is just sample.\n",
        "\n",
        "  '''\n",
        "\n",
        "  pass\n"
      ],
      "metadata": {
        "id": "SFxO1CDd_Jxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def SUBTASK2():\n",
        "\n",
        "  '''\n",
        "     Sample a dataset of size $n=1500$.\n",
        "     Find the best emprical risk minimizer hypothesis using code snippted provided for different k values from 1, 2, 3,.., 10.\n",
        "     Plot the mean and standard deviation of emprirical, true error over 10 independent runs.\n",
        "     Plot these both error values against k.\n",
        "\n",
        "     You can change the inputs as per your need and requirements. This is just sample.\n",
        "\n",
        "  '''\n",
        "  pass\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-TgmxVHz_JvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kYyKbbJ7_JmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TASK 2</h1>"
      ],
      "metadata": {
        "id": "nh_CWe4iA0NZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 2**:                                                      **(40 Marks)**\n",
        "\n",
        "In this question, we will test the effect of different noise on the polynomial curve fitting with regression.\n",
        "\n",
        "Let the given function is $f(x) = \\frac{2cos(x)}{-\\pi}+\\frac{(2x)}{(2\\pi)}+\\frac{2cos(3x)}{(-3\\pi)} + (z\\times \\text{Noise}$) where $x$ ranges from $-10$ to $10$  and $z$ is the scaling factor for the additive noise.  \n",
        "\n",
        "1. Noise$\\sim \\mathcal{N}(\\mu=0,\\sigma=1)$ and added with a scaling factor of 0.1 in the function f(x). Perform the next steps using gaussian noise.</br>\n",
        "\n",
        "  a. Generate $50$ data points from the given f(x) and gaussian noise.  **(1 Marks)**</br>\n",
        "  b. Fit a polynomial regresser for the above generated data using gradient descent optimizer with momentum  **(8 Marks)**.\n",
        "  \n",
        "  Try it with multiple degrees of polynomial $\\mathcal{M}$ where $\\mathcal{M}$ = [1,20] and report the empirical error for each $\\mathcal{M}$.  **(2 Marks)**</br>\n",
        "\n",
        "  c. Report the best and worst fit degree along with proper observations and graphs.  **(2 Marks for graphs, 3 Marks for observations)**</br>\n",
        "\n",
        "  d.  Repeat the previous experiments with more number of data points and report your findings.  **(2 Marks + 1 Marks)** </br>\n",
        "\n",
        "  e. Plot the bias and variance with respect to $M$.  **(2 Marks)**</br>\n",
        "  f. Plot the bias and variance with respect to number of datapoints. **(2 Marks)**</br>\n",
        "\n",
        "\n",
        "2. Noise$\\sim \\mathcal{P}(\\lambda=2)$ and added with a scaling factor of 0.1 in the function f(x). Perform the next steps using poisson noise.</br>\n",
        "\n",
        "  a. Generate $50$ data points from the given f(x) and possion noise. **(1 Marks)**</br>\n",
        "  b. Fit a polynomial regresser for the above generated data using gradient descent optimizer with momentum. **(Already graded)**\n",
        "  Try it with multiple degrees of polynomial $\\mathcal{M}$ where $\\mathcal{M}$ = [1,20] and report the empirical error for each $\\mathcal{M}$. **(2 Marks)** </br>\n",
        "  c. Report the best and worst fit degree along with proper observations and graphs. **(2 Marks for graphs, 3 Marks for observations)**</br>\n",
        "  d.  Repeat the previous experiments with more number of data points and report your findings.**(2 Marks + 1 Marks)** </br>\n",
        "  e. Plot the bias and variance with respect to $M$. **(2 Marks)**</br>\n",
        "  f. Plot the bias and variance with respect to number of datapoints. **(2 Marks)**</br>\n",
        "\n",
        "3. Compare for both types of noise added to the function f(x) and report your observations. **(2 Marks)**\n",
        "\n",
        "Note: Code the gradient descent from scratch for full credit. 50% marks will be deducted if you use inbuilt library functions for optimizer and regression.\n",
        "\n",
        "For momentum based gradient descent optimizer refer the following equations as hint:\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "here, $w_{t+1}$: weights at time $(t+1)$ </br>\n",
        "$w_t$: weights at time $t$</br>\n",
        "$\\alpha$ : learning rate </br>\n",
        "$m_t$: momentum at time $t$</br>\n",
        "$m_{t-1}$: momentum at time $(t-1)$ where $m_0$=0</br>\n",
        "$\\beta$ : moving average parameter (constant) </br>\n",
        "$\\delta L$/$\\delta w$: Loss $L$ derivative w.r.t weights $w$ </br>\n",
        "\n",
        "**Use of sci-kit or any direct implementation of linear regression is striclty probhibted as it will lead to 50% penalty. You can use numpy and pandas.** </br>\n",
        "Write your code by creating cells below.\n"
      ],
      "metadata": {
        "id": "t1Oy_Gn4zNXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution with Gaussian Noise"
      ],
      "metadata": {
        "id": "439JrFDKhSN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_error(Y_true,Y_pred):\n",
        "  pass"
      ],
      "metadata": {
        "id": "hZDYR1a2jUIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data_with_gaussian_noise(scaling_factor, total_number_of_data_points):\n",
        "\n",
        "  pass\n",
        "\n"
      ],
      "metadata": {
        "id": "wAYT9XLqA3ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def polynomial_regressor_gaus(degree):\n",
        "  pass\n"
      ],
      "metadata": {
        "id": "auZg0gT6guQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Bw4wdKEhn_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment_with_different_total_number_of_points_gaus():\n",
        "\n",
        "  pass"
      ],
      "metadata": {
        "id": "RmbFIlRrhn85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_bias_and_variance():\n",
        "  pass"
      ],
      "metadata": {
        "id": "3UQtdMG3hn6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution with Poison Noise"
      ],
      "metadata": {
        "id": "80mDFVxhhkKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data_with_gaussian_noise(scaling_factor, total_number_of_data_points):\n",
        "\n",
        "  pass\n"
      ],
      "metadata": {
        "id": "OAYQm8QFguNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def polynomial_regressor_poison(degree):\n",
        "  pass\n"
      ],
      "metadata": {
        "id": "akz4onvThnl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment_with_different_total_number_of_points_poison():\n",
        "\n",
        "  pass"
      ],
      "metadata": {
        "id": "PDJsdDi5hnjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment_with_different_degrees_poison(max_degree):\n",
        "\n",
        "  pass"
      ],
      "metadata": {
        "id": "OVJCwYouhnhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AA5Q4faWhnfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TASK 3</h1>"
      ],
      "metadata": {
        "id": "MdVTh8islJiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 3**:                                                      **(20 Marks)**\n",
        "Given a concept class $h$ which comprises of axis-aligned rectangles with\n",
        "$a \\leq x \\leq b$ and $c \\leq y \\leq d$ where $a$, $b$, $c$, $d$ are real numbers with condition 0 $\\leq p \\leq q \\leq $ 100 and 0 $\\leq r \\leq s \\leq $ 100. Implement the following:\n",
        "\n",
        "1. Generate a random concept $h$ with ${p,q,r,s}$ parameters for a rectangle.</br> **(1 Marks)**\n",
        "2. Generate a dataset with atleast 100 i.i.d samples ($x$,$y$) drawn from uniform distribution. Label them with the generated concept $h$ in the previous step.\n",
        "The samples inside the rectangle should be labelled as 1 and 0 otherwise. The points on the boundary of rectangle should be labelled as 1. **(1+1=2 Marks)**\n",
        "\n",
        "Note: Make sure to have good enough points for both labels 1 and 0.</br>\n",
        "3. Write a function to generate the hypothesis $h_1$ for the given data and calculate its empirical error. **(6+2=8 Marks)**</br>\n",
        "4. Plot the concept $h$ (true hypothesis) and  generated hypothesis $h_1$ on the generated data. **(1 Marks)**</br>\n",
        "5. Now, again sample 100 more points from the uniform distribution and check the empirical error with hypothesis $h_1$. **(1+1=2 Marks)**</br>\n",
        "6. Add these 100 samples from step 5. in the original dataset, and reestimate the hypothesis $h_2$ and calculate error on $h_2$. **(1+1=2 Marks)** <br>\n",
        "7. Plot $h$, $h_1$ ,$h_2$ on the dataset and report your observations. **(1 + 3 =4Marks)**\n"
      ],
      "metadata": {
        "id": "iS0ZUM_aka9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code here for Task 3"
      ],
      "metadata": {
        "id": "B88Aek8hlFFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Thanks"
      ],
      "metadata": {
        "id": "jY7Bq7zYCC8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DO PREPARE A SEPARATE REPORT (in PDF format) for all your observations in each question. You can report any other observations as well and use your creativity to understand the concepts."
      ],
      "metadata": {
        "id": "rqdjZFfABxO1"
      }
    }
  ]
}