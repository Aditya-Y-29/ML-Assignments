{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26c59895-e44d-438e-b9c0-4a340c0db435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n",
      "Final parameters: [-6.09148179e+26 -2.47353390e+27 -1.07223387e+28]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def polynomial_features(X, degree):\n",
    "    \"\"\"Add polynomial features up to the specified degree.\"\"\"\n",
    "    X_poly = np.ones((len(X), 1))\n",
    "    for d in range(1, degree + 1):\n",
    "        X_poly = np.c_[X_poly, X ** d]\n",
    "    return X_poly\n",
    "\n",
    "def hypothesis(X, theta):\n",
    "    \"\"\"Calculate the hypothesis function.\"\"\"\n",
    "    return np.dot(X, theta)\n",
    "\n",
    "def cost_function(X, y, theta):\n",
    "    \"\"\"Calculate the cost function (mean squared error).\"\"\"\n",
    "    m = len(y)\n",
    "    h = hypothesis(X, theta)\n",
    "    return (1 / (2 * m)) * np.sum((h - y) ** 2)\n",
    "\n",
    "def gradient_descent(X, y, theta, alpha, num_iters):\n",
    "    \"\"\"Perform gradient descent to minimize the cost function.\"\"\"\n",
    "    m = len(y)\n",
    "    cost_history = []\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        h = hypothesis(X, theta)\n",
    "        gradient = (1 / m) * np.dot(X.T, (h - y))\n",
    "        theta -= alpha * gradient\n",
    "        cost_history.append(cost_function(X, y, theta))\n",
    "\n",
    "    return theta, cost_history\n",
    "\n",
    "# Example data\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # Feature matrix\n",
    "y = np.array([2, 3, 4, 5, 6])                # Target vector\n",
    "degree = 2                                   # Degree of polynomial\n",
    "\n",
    "# Add polynomial features\n",
    "X_poly = polynomial_features(X, degree)\n",
    "print(X_poly.shape)\n",
    "# Initialize parameters\n",
    "theta = np.zeros(X_poly.shape[1])\n",
    "\n",
    "# Set hyperparameters\n",
    "alpha = 0.01\n",
    "num_iters = 1000\n",
    "\n",
    "# Perform gradient descent\n",
    "theta_final, cost_history = gradient_descent(X_poly, y, theta, alpha, num_iters)\n",
    "\n",
    "print(\"Final parameters:\", theta_final)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
